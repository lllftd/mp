#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆçˆ¬è™«è„šæœ¬ - ä¸€é”®å®Œæˆï¼šçˆ¬è™« â†’ AIè½¬è¿° â†’ æ°´å°æ¸…æ´— â†’ ä¸Šä¼ æ•°æ®åº“
"""
import datetime
import time
import random
import json
import csv
import os
import sys
import requests
import threading
import psutil
from urllib.parse import quote
from DrissionPage._pages.chromium_page import ChromiumPage

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import Config
from ai_paraphrase import get_ai_paraphraser
from database import db
from batch_upload_tweets import insert_tweet, prepare_tweet_data
from username_generator import get_random_username
from image_processor import ImageProcessor
from performance_monitor import get_crawler_performance_monitor

try:
    from PIL import Image
    import numpy as np
    import cv2
    IMAGE_PROCESSING_AVAILABLE = True
except ImportError:
    IMAGE_PROCESSING_AVAILABLE = False
    print("è­¦å‘Š: PIL/OpenCVæœªå®‰è£…ï¼Œæ°´å°æ¸…æ´—åŠŸèƒ½å°†ä½¿ç”¨AIæ–¹å¼")


class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self, warning_threshold_gb=10.0, critical_threshold_gb=5.0):
        """
        åˆå§‹åŒ–å†…å­˜ç›‘æ§å™¨
        
        Args:
            warning_threshold_gb: è­¦å‘Šé˜ˆå€¼ï¼ˆGBï¼‰ï¼Œå¯ç”¨å†…å­˜ä½äºæ­¤å€¼æ—¶å‘å‡ºè­¦å‘Š
            critical_threshold_gb: ä¸¥é‡è­¦å‘Šé˜ˆå€¼ï¼ˆGBï¼‰ï¼Œå¯ç”¨å†…å­˜ä½äºæ­¤å€¼æ—¶å‘å‡ºä¸¥é‡è­¦å‘Š
        """
        self.warning_threshold = warning_threshold_gb * 1024 * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        self.critical_threshold = critical_threshold_gb * 1024 * 1024 * 1024
        self.process = psutil.Process(os.getpid())
        self.monitoring = False
        self.monitor_thread = None
        self.last_check_time = 0
        self.check_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        
        # æ ¹æ®æ¨¡å‹å¤§å°è°ƒæ•´å†…å­˜é˜ˆå€¼
        # 7bæ¨¡å‹éœ€è¦çº¦8-16GBï¼Œ32bæ¨¡å‹éœ€è¦çº¦32GB+
        # ä¿å®ˆè®¾ç½®ï¼š7bæ¨¡å‹è­¦å‘Šé˜ˆå€¼10GBï¼Œä¸¥é‡é˜ˆå€¼5GB
        # 32bæ¨¡å‹è­¦å‘Šé˜ˆå€¼20GBï¼Œä¸¥é‡é˜ˆå€¼10GB
        if '32b' in Config.LLM_MODEL.lower():
            # 32bæ¨¡å‹éœ€è¦æ›´å¤šå†…å­˜
            self.warning_threshold = 20.0 * 1024 * 1024 * 1024
            self.critical_threshold = 10.0 * 1024 * 1024 * 1024
        else:
            # 7bæˆ–æ›´å°çš„æ¨¡å‹
            self.warning_threshold = warning_threshold_gb * 1024 * 1024 * 1024
            self.critical_threshold = critical_threshold_gb * 1024 * 1024 * 1024
        
    def format_bytes(self, bytes_size):
        """æ ¼å¼åŒ–å­—èŠ‚å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_size < 1024.0:
                return f"{bytes_size:.2f} {unit}"
            bytes_size /= 1024.0
        return f"{bytes_size:.2f} PB"
    
    def get_memory_info(self):
        """è·å–å†…å­˜ä¿¡æ¯"""
        try:
            system_memory = psutil.virtual_memory()
            process_memory = self.process.memory_info()
            
            # è·å–Ollamaè¿›ç¨‹å†…å­˜
            ollama_memory = 0
            ollama_count = 0
            for proc in psutil.process_iter(['pid', 'name', 'memory_info']):
                try:
                    if 'ollama' in proc.info['name'].lower():
                        ollama_memory += proc.info['memory_info'].rss
                        ollama_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            return {
                'system': {
                    'total': system_memory.total,
                    'available': system_memory.available,
                    'used': system_memory.used,
                    'percent': system_memory.percent
                },
                'process': {
                    'rss': process_memory.rss,
                    'vms': process_memory.vms
                },
                'ollama': {
                    'memory': ollama_memory,
                    'count': ollama_count
                }
            }
        except Exception as e:
            return None
    
    def check_memory(self, print_info=True, raise_on_critical=True):
        """
        æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
        
        Args:
            print_info: æ˜¯å¦æ‰“å°å†…å­˜ä¿¡æ¯
            raise_on_critical: å†…å­˜ä¸¥é‡ä¸è¶³æ—¶æ˜¯å¦æŠ›å‡ºå¼‚å¸¸
            
        Returns:
            bool: Trueè¡¨ç¤ºå†…å­˜å……è¶³ï¼ŒFalseè¡¨ç¤ºå†…å­˜ä¸è¶³
        """
        memory_info = self.get_memory_info()
        if not memory_info:
            return True
        
        available = memory_info['system']['available']
        process_rss = memory_info['process']['rss']
        ollama_memory = memory_info['ollama']['memory']
        
        # æ£€æŸ¥ç³»ç»Ÿå¯ç”¨å†…å­˜
        is_warning = available < self.warning_threshold
        is_critical = available < self.critical_threshold
        
        if print_info:
            print(f"\n[å†…å­˜ç›‘æ§] ç³»ç»Ÿå¯ç”¨: {self.format_bytes(available)} | "
                  f"è¿›ç¨‹: {self.format_bytes(process_rss)} | "
                  f"Ollama: {self.format_bytes(ollama_memory)} ({memory_info['ollama']['count']}ä¸ªè¿›ç¨‹)")
        
        if is_critical:
            error_msg = f"ç³»ç»Ÿå¯ç”¨å†…å­˜ä¸¥é‡ä¸è¶³: {self.format_bytes(available)} (ä½äºé˜ˆå€¼ {self.format_bytes(self.critical_threshold)})"
            print(f"\n[ä¸¥é‡è­¦å‘Š] {error_msg}")
            print("   å»ºè®®: 1. å…³é—­å…¶ä»–ç¨‹åº 2. é‡å¯OllamaæœåŠ¡ 3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
            print("   ä¸ºé˜²æ­¢æ¨¡å‹å´©æºƒï¼Œç¨‹åºå°†ç»ˆæ­¢")
            
            if raise_on_critical:
                raise MemoryError(error_msg)
            return False
        elif is_warning:
            print(f"\n[è­¦å‘Š] ç³»ç»Ÿå¯ç”¨å†…å­˜è¾ƒä½: {self.format_bytes(available)} (ä½äºé˜ˆå€¼ {self.format_bytes(self.warning_threshold)})")
            print("   å»ºè®®é‡Šæ”¾å†…å­˜æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
            return True
        
        return True
    
    def start_monitoring(self):
        """å¼€å§‹åå°ç›‘æ§"""
        if self.monitoring:
            return
        
        self.monitoring = True
        
        def monitor_loop():
            while self.monitoring:
                try:
                    time.sleep(self.check_interval)
                    if self.monitoring:
                        # åå°ç›‘æ§ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªæ‰“å°è­¦å‘Š
                        self.check_memory(print_info=True, raise_on_critical=False)
                except Exception as e:
                    print(f"[å†…å­˜ç›‘æ§] æ£€æŸ¥å‡ºé”™: {e}")
        
        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()
        print("[å†…å­˜ç›‘æ§] å·²å¯åŠ¨åå°ç›‘æ§")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
    
    def print_summary(self):
        """æ‰“å°å†…å­˜ä½¿ç”¨æ‘˜è¦"""
        memory_info = self.get_memory_info()
        if not memory_info:
            return
        
        print("\n" + "=" * 60)
        print("å†…å­˜ä½¿ç”¨æ‘˜è¦")
        print("=" * 60)
        print(f"ç³»ç»Ÿæ€»å†…å­˜: {self.format_bytes(memory_info['system']['total'])}")
        print(f"ç³»ç»Ÿå¯ç”¨å†…å­˜: {self.format_bytes(memory_info['system']['available'])}")
        print(f"ç³»ç»Ÿå·²ä½¿ç”¨: {self.format_bytes(memory_info['system']['used'])} ({memory_info['system']['percent']:.2f}%)")
        print(f"å½“å‰è¿›ç¨‹å†…å­˜: {self.format_bytes(memory_info['process']['rss'])}")
        print(f"Ollamaè¿›ç¨‹å†…å­˜: {self.format_bytes(memory_info['ollama']['memory'])} ({memory_info['ollama']['count']}ä¸ªè¿›ç¨‹)")
        print("=" * 60)


class WatermarkRemover:
    """æ°´å°æ¸…æ´—å·¥å…·"""
    
    def __init__(self):
        self.use_ai = not IMAGE_PROCESSING_AVAILABLE
        self.ai_paraphraser = get_ai_paraphraser()
    
    def remove_watermark_ai(self, image_url: str) -> str:
        """ä½¿ç”¨AIæ¸…æ´—æ°´å°ï¼ˆå¦‚æœå›¾åƒå¤„ç†ä¸å¯ç”¨ï¼‰"""
        # å¯¹äºAIæ–¹å¼ï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›åŸURLï¼Œå› ä¸ºAIä¸»è¦ç”¨äºå†…å®¹è½¬è¿°
        # å®é™…çš„æ°´å°æ¸…æ´—éœ€è¦ä¸“é—¨çš„å›¾åƒå¤„ç†AIæ¨¡å‹
        return image_url
    
    def is_grid_image(self, img_cv):
        """
        æ£€æµ‹æ˜¯å¦ä¸ºå››æ ¼æ‹¼å›¾
        é€šè¿‡æ£€æµ‹å›¾ç‰‡ä¸­çš„åˆ†å‰²çº¿æ¥åˆ¤æ–­
        """
        h, w = img_cv.shape[:2]
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        
        # æ£€æµ‹å‚ç›´å’Œæ°´å¹³åˆ†å‰²çº¿
        # ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        
        # æ£€æµ‹å‚ç›´åˆ†å‰²çº¿ï¼ˆä¸­é—´ä½ç½®ï¼‰
        vertical_mid = w // 2
        vertical_region = edges[:, max(0, vertical_mid-10):min(w, vertical_mid+10)]
        vertical_line_score = np.sum(vertical_region > 0) / (h * 20)  # å½’ä¸€åŒ–
        
        # æ£€æµ‹æ°´å¹³åˆ†å‰²çº¿ï¼ˆä¸­é—´ä½ç½®ï¼‰
        horizontal_mid = h // 2
        horizontal_region = edges[max(0, horizontal_mid-10):min(h, horizontal_mid+10), :]
        horizontal_line_score = np.sum(horizontal_region > 0) / (w * 20)  # å½’ä¸€åŒ–
        
        # å¦‚æœå‚ç›´å’Œæ°´å¹³éƒ½æœ‰æ˜æ˜¾çš„åˆ†å‰²çº¿ï¼Œå¯èƒ½æ˜¯å››æ ¼æ‹¼å›¾
        # é˜ˆå€¼å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        is_grid = vertical_line_score > 0.3 and horizontal_line_score > 0.3
        
        return is_grid
    
    def split_grid_image(self, img_cv, base_save_path: str) -> list:
        """
        å°†å››æ ¼æ‹¼å›¾æ‹†åˆ†æˆ4å¼ å•ç‹¬çš„å›¾ç‰‡ï¼Œå¹¶å¯¹æ¯ä¸ªæ ¼å­è¿›è¡Œæ°´å°æ¸…æ´—
        
        Args:
            img_cv: OpenCVæ ¼å¼çš„å›¾ç‰‡
            base_save_path: åŸºç¡€ä¿å­˜è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            æ‹†åˆ†åçš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        h, w = img_cv.shape[:2]
        
        # è®¡ç®—æ¯ä¸ªæ ¼å­çš„å°ºå¯¸
        cell_h = h // 2
        cell_w = w // 2
        
        # æ‹†åˆ†4ä¸ªæ ¼å­
        # å·¦ä¸Šã€å³ä¸Šã€å·¦ä¸‹ã€å³ä¸‹
        cells = [
            (0, cell_h, 0, cell_w),           # å·¦ä¸Š
            (0, cell_h, cell_w, w),          # å³ä¸Š
            (cell_h, h, 0, cell_w),          # å·¦ä¸‹
            (cell_h, h, cell_w, w)           # å³ä¸‹
        ]
        
        split_paths = []
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(base_save_path), exist_ok=True)
        
        # è·å–æ–‡ä»¶æ‰©å±•å
        ext = os.path.splitext(base_save_path)[1] or '.jpg'
        base_name = os.path.splitext(os.path.basename(base_save_path))[0]
        base_dir = os.path.dirname(base_save_path)
        
        for idx, (y1, y2, x1, x2) in enumerate(cells):
            # æå–å•ä¸ªæ ¼å­
            cell_img = img_cv[y1:y2, x1:x2]
            
            # å¯¹æ¯ä¸ªæ ¼å­è¿›è¡Œæ°´å°æ¸…æ´—
            # æ£€æµ‹æ–‡å­—åŒºåŸŸ
            text_mask = self.detect_text_regions(cell_img)
            
            # æ£€æŸ¥maskæ˜¯å¦æœ‰å†…å®¹
            if np.sum(text_mask) == 0:
                # æ²¡æœ‰æ£€æµ‹åˆ°æ–‡å­—ï¼Œä½¿ç”¨åŸå›¾
                cleaned_cell = cell_img
            else:
                # é™åˆ¶inpaintingåŠå¾„ï¼Œé¿å…è¿‡åº¦å¤„ç†
                cell_h, cell_w = cell_img.shape[:2]
                cell_size = max(cell_h, cell_w)
                inpaint_radius = min(3, max(1, cell_size // 400))
                
                # ä½¿ç”¨inpaintingå¡«å……
                cleaned_cell = cv2.inpaint(cell_img, text_mask, inpaint_radius, cv2.INPAINT_NS)
            
            # ç”Ÿæˆä¿å­˜è·¯å¾„
            cell_path = os.path.join(base_dir, f"{base_name}_grid_{idx+1}{ext}")
            
            # è½¬æ¢ä¸ºRGBå¹¶ä¿å­˜
            cell_rgb = cv2.cvtColor(cleaned_cell, cv2.COLOR_BGR2RGB)
            cell_pil = Image.fromarray(cell_rgb)
            cell_pil.save(cell_path, quality=95)
            
            split_paths.append(cell_path)
        
        return split_paths
    
    def detect_text_regions(self, img_cv):
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„æ–‡å­—åŒºåŸŸï¼ˆæ°´å°ã€é¤å…åç­‰ï¼‰
        ä¼˜åŒ–ç‰ˆæœ¬ï¼šå‡å°‘è¯¯æ£€ï¼Œé¿å…è¿‡åº¦å¤„ç†å¯¼è‡´é©¬èµ›å…‹
        
        ç­–ç•¥ï¼š
        1. åªæ£€æµ‹æ˜æ˜¾çš„æ°´å°åŒºåŸŸï¼ˆè§’è½å’Œä¸­å¿ƒæ˜æ˜¾æ–‡å­—ï¼‰
        2. ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼ï¼Œé¿å…è¯¯æ£€æ­£å¸¸å†…å®¹
        3. é™åˆ¶å¤„ç†åŒºåŸŸå¤§å°ï¼Œé¿å…è¿‡åº¦å¤„ç†
        """
        h, w = img_cv.shape[:2]
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        
        # åˆ›å»ºå…¨å›¾mask
        mask = np.zeros((h, w), np.uint8)
        
        # ç­–ç•¥1: åªæ£€æµ‹è§’è½çš„æ°´å°ï¼ˆå°çº¢ä¹¦logoç­‰ï¼‰ - ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼
        corner_regions = [
            (0, int(h*0.15), int(w*0.85), w),      # å³ä¸Šè§’
            (int(h*0.85), h, int(w*0.85), w),     # å³ä¸‹è§’
            (0, int(h*0.15), 0, int(w*0.15)),     # å·¦ä¸Šè§’
            (int(h*0.85), h, 0, int(w*0.15)),     # å·¦ä¸‹è§’
        ]
        
        for y1, y2, x1, x2 in corner_regions:
            if x2 > x1 and y2 > y1:  # ç¡®ä¿åŒºåŸŸæœ‰æ•ˆ
                corner_gray = gray[y1:y2, x1:x2]
                # ä½¿ç”¨æ›´é«˜çš„é˜ˆå€¼ï¼Œåªæ£€æµ‹æ˜æ˜¾çš„ç™½è‰²æ–‡å­—
                _, corner_thresh = cv2.threshold(corner_gray, 220, 255, cv2.THRESH_BINARY)
                mask[y1:y2, x1:x2] = cv2.bitwise_or(
                    mask[y1:y2, x1:x2],
                    corner_thresh
                )
        
        # ç­–ç•¥2: æ£€æµ‹ä¸­å¿ƒåŒºåŸŸæ˜æ˜¾çš„æ–‡å­—ï¼ˆä½†ä½¿ç”¨æ›´ä¸¥æ ¼çš„è§„åˆ™ï¼‰
        # åªåœ¨ä¸­å¿ƒåŒºåŸŸæ£€æµ‹ï¼Œä¸”ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼
        center_h_start = int(h * 0.35)
        center_h_end = int(h * 0.65)
        center_w_start = int(w * 0.25)
        center_w_end = int(w * 0.75)
        
        if center_h_end > center_h_start and center_w_end > center_w_start:
            center_region = gray[center_h_start:center_h_end, center_w_start:center_w_end]
            
            # æ£€æµ‹é«˜å¯¹æ¯”åº¦çš„æ–‡å­—åŒºåŸŸï¼ˆç™½è‰²æ–‡å­—åœ¨æ·±è‰²èƒŒæ™¯ï¼‰
            _, center_white = cv2.threshold(center_region, 240, 255, cv2.THRESH_BINARY)
            # æ£€æµ‹æ·±è‰²æ–‡å­—åœ¨æµ…è‰²èƒŒæ™¯
            _, center_black = cv2.threshold(center_region, 30, 255, cv2.THRESH_BINARY_INV)
            
            # åˆå¹¶ä¸­å¿ƒåŒºåŸŸçš„æ£€æµ‹
            center_mask = cv2.bitwise_or(center_white, center_black)
            
            # å½¢æ€å­¦æ“ä½œï¼Œè¿æ¥æ–‡å­—ç¬”ç”»ï¼Œä½†ä¸è¦è¿‡åº¦è†¨èƒ€
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            center_mask = cv2.morphologyEx(center_mask, cv2.MORPH_CLOSE, kernel, iterations=1)
            
            # è¿‡æ»¤æ‰å¤ªå°çš„åŒºåŸŸï¼ˆå¯èƒ½æ˜¯å™ªç‚¹ï¼‰
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(center_mask, connectivity=8)
            center_filtered = np.zeros_like(center_mask)
            
            # æé«˜æœ€å°é¢ç§¯é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ£€
            min_area = max(100, (h * w) // 10000)  # åŠ¨æ€æœ€å°é¢ç§¯
            
            for i in range(1, num_labels):
                area = stats[i, cv2.CC_STAT_AREA]
                # æ£€æŸ¥å®½é«˜æ¯”ï¼Œæ–‡å­—é€šå¸¸å®½é«˜æ¯”å¤§äº1
                width = stats[i, cv2.CC_STAT_WIDTH]
                height = stats[i, cv2.CC_STAT_HEIGHT]
                aspect_ratio = width / height if height > 0 else 0
                
                # åªä¿ç•™é¢ç§¯è¶³å¤Ÿå¤§ä¸”å®½é«˜æ¯”åˆç†çš„åŒºåŸŸï¼ˆæ–‡å­—ç‰¹å¾ï¼‰
                if area >= min_area and (aspect_ratio > 1.2 or aspect_ratio < 0.8):
                    center_filtered[labels == i] = 255
            
            # å°†ä¸­å¿ƒåŒºåŸŸçš„æ£€æµ‹ç»“æœåŠ å…¥mask
            mask[center_h_start:center_h_end, center_w_start:center_w_end] = \
                cv2.bitwise_or(
                    mask[center_h_start:center_h_end, center_w_start:center_w_end],
                    center_filtered
                )
        
        # æœ€åå»å™ªï¼šåªä¿ç•™è¾ƒå¤§çš„è¿é€šåŒºåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)
        filtered_mask = np.zeros_like(mask)
        
        # è®¡ç®—å›¾ç‰‡æ€»é¢ç§¯ï¼ŒåŠ¨æ€è°ƒæ•´æœ€å°åŒºåŸŸ
        total_area = h * w
        min_area = max(50, total_area // 5000)  # è‡³å°‘å æ€»é¢ç§¯çš„0.02%
        
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if area >= min_area:
                filtered_mask[labels == i] = 255
        
        # è½»å¾®è†¨èƒ€ï¼Œç¡®ä¿æ–‡å­—è¾¹ç¼˜ä¹Ÿè¢«è¦†ç›–ï¼ˆä½†ä¸è¦è¿‡åº¦ï¼‰
        kernel_expand = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        filtered_mask = cv2.dilate(filtered_mask, kernel_expand, iterations=1)
        
        # é™åˆ¶å¤„ç†åŒºåŸŸï¼šå¦‚æœmaskè¦†ç›–é¢ç§¯è¶…è¿‡å›¾ç‰‡çš„10%ï¼Œå¯èƒ½æ˜¯è¯¯æ£€ï¼Œå‡å°‘å¤„ç†
        mask_area_ratio = np.sum(filtered_mask > 0) / total_area
        if mask_area_ratio > 0.1:
            # å¦‚æœæ£€æµ‹åˆ°çš„åŒºåŸŸå¤ªå¤§ï¼Œåªä¿ç•™æœ€å¤§çš„å‡ ä¸ªåŒºåŸŸ
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(filtered_mask, connectivity=8)
            areas = [(i, stats[i, cv2.CC_STAT_AREA]) for i in range(1, num_labels)]
            areas.sort(key=lambda x: x[1], reverse=True)
            
            # åªä¿ç•™å‰5ä¸ªæœ€å¤§çš„åŒºåŸŸ
            filtered_mask = np.zeros_like(filtered_mask)
            for i, _ in areas[:5]:
                filtered_mask[labels == i] = 255
        
        return filtered_mask
    
    def remove_watermark_image(self, image_url: str, save_path: str = None) -> str:
        """ä½¿ç”¨å›¾åƒå¤„ç†æ¸…æ´—æ°´å°å’Œæ–‡å­—"""
        if not IMAGE_PROCESSING_AVAILABLE:
            return image_url
        
        try:
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url, timeout=30)
            if response.status_code != 200:
                return image_url
            
            # è½¬æ¢ä¸ºPIL Image
            from io import BytesIO
            img = Image.open(BytesIO(response.content))
            img_array = np.array(img)
            
            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            if len(img_array.shape) == 3:
                img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            else:
                img_cv = img_array
            
            h, w = img_cv.shape[:2]  # è·å–å›¾ç‰‡å°ºå¯¸
            
            # æ£€æµ‹æ˜¯å¦ä¸ºå››æ ¼æ‹¼å›¾
            if self.is_grid_image(img_cv):
                print(f"æ£€æµ‹åˆ°å››æ ¼æ‹¼å›¾ï¼Œæ­£åœ¨æ‹†åˆ†...")
                if save_path:
                    split_paths = self.split_grid_image(img_cv, save_path)
                    print(f"å·²æ‹†åˆ†ä¸º {len(split_paths)} å¼ å›¾ç‰‡")
                    # è¿”å›æ‰€æœ‰æ‹†åˆ†åçš„å›¾ç‰‡è·¯å¾„ï¼ˆé€—å·åˆ†éš”ï¼‰
                    return ",".join(split_paths) if split_paths else image_url
                else:
                    # å¦‚æœæ²¡æœ‰æŒ‡å®šä¿å­˜è·¯å¾„ï¼Œå…ˆä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶å†æ‹†åˆ†
                    temp_path = f"temp_grid_{int(time.time())}.jpg"
                    split_paths = self.split_grid_image(img_cv, temp_path)
                    return ",".join(split_paths) if split_paths else image_url
            
            # ä¸æ˜¯å››æ ¼æ‹¼å›¾ï¼Œæ­£å¸¸å¤„ç†æ°´å°
            # æ£€æµ‹æ–‡å­—åŒºåŸŸï¼ˆåŒ…æ‹¬ä¸­å¿ƒåŒºåŸŸçš„é¤å…åç­‰ï¼‰
            text_mask = self.detect_text_regions(img_cv)
            
            # æ£€æŸ¥maskæ˜¯å¦æœ‰å†…å®¹ï¼Œå¦‚æœmaskä¸ºç©ºåˆ™ç›´æ¥è¿”å›åŸå›¾
            if np.sum(text_mask) == 0:
                # æ²¡æœ‰æ£€æµ‹åˆ°æ–‡å­—ï¼Œç›´æ¥ä¿å­˜åŸå›¾
                if save_path:
                    os.makedirs(os.path.dirname(save_path), exist_ok=True)
                    img.save(save_path, quality=95)
                    return save_path
                return image_url
            
            # é™åˆ¶inpaintingçš„åŠå¾„ï¼Œé¿å…è¿‡åº¦å¤„ç†å¯¼è‡´é©¬èµ›å…‹
            # æ ¹æ®å›¾ç‰‡å¤§å°åŠ¨æ€è°ƒæ•´åŠå¾„
            img_size = max(h, w)
            inpaint_radius = min(3, max(1, img_size // 400))  # åŠå¾„åœ¨1-3ä¹‹é—´
            
            # ä½¿ç”¨inpaintingæ™ºèƒ½å¡«å……æ–‡å­—åŒºåŸŸ
            # INPAINT_NS ç®—æ³•æ•ˆæœæ›´è‡ªç„¶ï¼Œé€‚åˆå¡«å……æ–‡å­—åŒºåŸŸ
            result = cv2.inpaint(img_cv, text_mask, inpaint_radius, cv2.INPAINT_NS)
            
            # ä¸å†è¿›è¡ŒäºŒæ¬¡å¤„ç†ï¼Œé¿å…è¿‡åº¦å¤„ç†å¯¼è‡´é©¬èµ›å…‹
            
            # è½¬æ¢å›PILå¹¶ä¿å­˜
            result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
            result_img = Image.fromarray(result_rgb)
            
            if save_path:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                result_img.save(save_path, quality=95)
                return save_path
            else:
                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                temp_path = f"temp_cleaned_{int(time.time())}.jpg"
                result_img.save(temp_path, quality=95)
                return temp_path
                
        except Exception as e:
            print(f"æ°´å°æ¸…æ´—å¤±è´¥: {e}")
            return image_url
    
    def download_image(self, image_url: str, save_path: str) -> str:
        """ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„"""
        try:
            response = requests.get(image_url, timeout=30)
            if response.status_code != 200:
                return ""
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            # ä¿å­˜å›¾ç‰‡
            with open(save_path, 'wb') as f:
                f.write(response.content)
            
            return save_path
        except Exception as e:
            print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ {image_url}: {e}")
            return ""
    
    def process_image(self, image_url: str, save_path: str = None) -> str:
        """å¤„ç†å›¾ç‰‡ï¼Œæ¸…æ´—æ°´å°"""
        if Config.REMOVE_WATERMARK:
            if IMAGE_PROCESSING_AVAILABLE:
                return self.remove_watermark_image(image_url, save_path)
            else:
                return self.remove_watermark_ai(image_url)
        elif save_path:
            return self.download_image(image_url, save_path)
        return image_url


class IntegratedSpider:
    """é›†æˆçˆ¬è™«ï¼šçˆ¬è™« + AIè½¬è¿° + æ°´å°æ¸…æ´— + ä¸Šä¼ """
    
    def __init__(self):
        self.page = ChromiumPage()
        self.setup_browser()
        self.request_count = 0
        self.last_request_time = 0
        self.ai_paraphraser = None
        self.image_processor = ImageProcessor()  # ä½¿ç”¨æ–°çš„å›¾ç‰‡æœç´¢å¤„ç†å™¨
        self.perf_monitor = get_crawler_performance_monitor()
        self.memory_monitor = MemoryMonitor(warning_threshold_gb=10.0, critical_threshold_gb=5.0)
        
        # è‡ªåŠ¨å¯ç”¨AIè½¬è¿°
        try:
            self.ai_paraphraser = get_ai_paraphraser()
            if not self.ai_paraphraser.check_ollama_connection():
                raise Exception("OllamaæœåŠ¡æœªè¿è¡Œ")
            if not self.ai_paraphraser.check_model_exists():
                raise Exception(f"æ¨¡å‹ {Config.LLM_MODEL} æœªä¸‹è½½")
            print("âœ… AIè½¬è¿°åŠŸèƒ½å·²å¯ç”¨")
        except Exception as e:
            print(f"âŒ AIè½¬è¿°åˆå§‹åŒ–å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿ï¼š")
            print("1. OllamaæœåŠ¡å·²è¿è¡Œ")
            print(f"2. æ¨¡å‹ {Config.LLM_MODEL} å·²ä¸‹è½½")
            print("è¿è¡Œ: python setup_ollama.py")
            raise
    
    def setup_browser(self):
        """è®¾ç½®æµè§ˆå™¨å‚æ•°"""
        user_agent = random.choice(Config.USER_AGENTS)
        headers = Config.DEFAULT_HEADERS.copy()
        headers['User-Agent'] = user_agent
        self.page.set.headers(headers)
        self.page.set.window.size(Config.WINDOW_WIDTH, Config.WINDOW_HEIGHT)
    
    def enforce_rate_limit(self):
        """å¼ºåˆ¶é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < Config.MIN_REQUEST_INTERVAL:
            sleep_time = Config.MIN_REQUEST_INTERVAL - time_since_last
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
        self.request_count += 1
        
        if self.request_count % Config.EXTRA_DELAY_INTERVAL == 0:
            extra_delay = random.uniform(Config.EXTRA_DELAY_MIN, Config.EXTRA_DELAY_MAX)
            time.sleep(extra_delay)
    
    def random_delay(self, min_delay=None, max_delay=None):
        """éšæœºå»¶è¿Ÿ"""
        if min_delay is None:
            min_delay = Config.DELAY_MIN
        if max_delay is None:
            max_delay = Config.DELAY_MAX
        delay = random.uniform(min_delay, max_delay)
        time.sleep(delay)
    
    def human_like_scroll(self):
        """æ¨¡æ‹Ÿäººç±»æ»šåŠ¨"""
        scroll_steps = random.randint(Config.SCROLL_STEPS_MIN, Config.SCROLL_STEPS_MAX)
        for i in range(scroll_steps):
            scroll_distance = random.randint(Config.SCROLL_DISTANCE_MIN, Config.SCROLL_DISTANCE_MAX)
            self.page.run_js(f"window.scrollBy(0, {scroll_distance})")
            time.sleep(random.uniform(Config.SCROLL_INTERVAL_MIN, Config.SCROLL_INTERVAL_MAX))
    
    def check_for_blocking(self):
        """æ£€æŸ¥æ˜¯å¦è¢«é˜»æ­¢"""
        try:
            page_text = self.page.html.lower()
            for indicator in Config.BLOCKING_INDICATORS:
                if indicator in page_text:
                    return True
            return False
        except:
            return False
    
    def handle_blocking(self):
        """å¤„ç†è¢«é˜»æ­¢çš„æƒ…å†µ"""
        wait_time = random.uniform(Config.BLOCKING_WAIT_MIN, Config.BLOCKING_WAIT_MAX)
        time.sleep(wait_time)
        try:
            self.page.refresh()
            self.page.wait.doc_loaded()
            time.sleep(random.uniform(3, 5))
        except:
            pass
    
    def get_note_detail(self, note_id, xsec_token, retry_count=0):
        """è·å–ç¬”è®°è¯¦æƒ…"""
        start_time = time.time()
        try:
            self.enforce_rate_limit()
            infourl = f"https://www.xiaohongshu.com/explore/{note_id}?xsec_token={xsec_token}&xsec_source=pc_search&source=web_explore_feed"
            print(f"æ­£åœ¨è·å–è¯¦æƒ…ï¼š{note_id}")
            
            self.random_delay(3, 6)
            self.page.get(infourl)
            self.page.wait.doc_loaded()
            
            if self.check_for_blocking():
                self.handle_blocking()
                if retry_count < Config.MAX_RETRIES:
                    return self.get_note_detail(note_id, xsec_token, retry_count + 1)
                else:
                    return "", "", ""
            
            self.human_like_scroll()
            
            # è·å–å›¾ç‰‡é“¾æ¥
            img_urls = []
            try:
                swiper_elements = self.page.eles('.swiper-wrapper')
                if swiper_elements:
                    images = swiper_elements[0].eles("tag:img")
                    for img in images:
                        try:
                            imgurl = img.attr("src")
                            if imgurl and imgurl not in img_urls:
                                img_urls.append(imgurl)
                        except:
                            pass
            except Exception as e:
                print(f"è·å–å›¾ç‰‡å¤±è´¥: {e}")
            
            # è·å–æ ‡é¢˜å’Œæè¿°
            title = ""
            desc = ""
            try:
                title_ele = self.page.ele("#detail-title")
                if title_ele:
                    title = title_ele.text.strip()
                    
                desc_ele = self.page.ele("#detail-desc")
                if desc_ele:
                    desc = desc_ele.text.strip()
            except Exception as e:
                print(f"è·å–æ ‡é¢˜æˆ–æè¿°å¤±è´¥: {e}")
            
            duration = time.time() - start_time
            self.perf_monitor.record_metric(
                'crawler.get_note_detail',
                duration,
                {
                    'memory_mb': self.perf_monitor.get_memory_usage(),
                    'cpu_percent': self.perf_monitor.get_cpu_usage(),
                    'note_id': note_id
                }
            )
            return title, desc, ",".join(img_urls)
            
        except Exception as e:
            duration = time.time() - start_time
            self.perf_monitor.record_metric(
                'crawler.get_note_detail.error',
                duration,
                {'error': str(e), 'note_id': note_id}
            )
            print(f"è·å–è¯¦æƒ…å¤±è´¥: {e}")
            if retry_count < Config.MAX_RETRIES:
                self.random_delay(8, 15)
                return self.get_note_detail(note_id, xsec_token, retry_count + 1)
            else:
                return "", "", ""
    
    def search_notes(self, keyword, pages):
        """æœç´¢ç¬”è®°"""
        start_time = time.time()
        # æ£€æŸ¥å†…å­˜
        self.memory_monitor.check_memory(print_info=True)
        try:
            self.page.listen.start("https://edith.xiaohongshu.com/api/sns/web/v1/search/notes")
            encoded_keyword = quote(keyword)
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={encoded_keyword}&source=web_explore_feed"
            
            print(f"æ­£åœ¨è®¿é—®æœç´¢é¡µé¢: {search_url}")
            self.page.get(search_url)
            self.page.wait.doc_loaded()
            self.random_delay(5, 8)
            
            responses = []
            
            for page_num in range(pages):
                try:
                    print(f"æ­£åœ¨çˆ¬å–ç¬¬ {page_num + 1} é¡µ")
                    
                    if self.check_for_blocking():
                        self.handle_blocking()
                        continue
                    
                    self.human_like_scroll()
                    
                    try:
                        packet = self.page.listen.wait(timeout=Config.REQUEST_TIMEOUT)
                        if packet and packet.response:
                            response_body = packet.response.body
                            if response_body:
                                responses.append(response_body)
                                print(f"æˆåŠŸæ•è·ç¬¬ {page_num + 1} é¡µæ•°æ®")
                    except Exception as e:
                        print(f"ç¬¬ {page_num + 1} é¡µæ•è·å¤±è´¥: {e}")
                    
                    if page_num < pages - 1:
                        page_delay = random.uniform(Config.PAGE_DELAY_MIN, Config.PAGE_DELAY_MAX)
                        time.sleep(page_delay)
                        # æ¯é¡µåæ£€æŸ¥å†…å­˜
                        self.memory_monitor.check_memory(print_info=True)
                        
                except KeyboardInterrupt:
                    print(f"\nâš ï¸  åœ¨ç¬¬ {page_num + 1} é¡µçˆ¬å–æ—¶è¢«ä¸­æ–­")
                    print(f"å·²è·å– {len(responses)} é¡µæ•°æ®")
                    raise
            
            duration = time.time() - start_time
            self.perf_monitor.record_metric(
                'crawler.search_notes',
                duration,
                {
                    'keyword': keyword,
                    'pages': pages,
                    'responses_count': len(responses),
                    'memory_mb': self.perf_monitor.get_memory_usage(),
                    'cpu_percent': self.perf_monitor.get_cpu_usage()
                }
            )
            return responses
            
        except Exception as e:
            duration = time.time() - start_time
            self.perf_monitor.record_metric(
                'crawler.search_notes.error',
                duration,
                {'error': str(e), 'keyword': keyword, 'pages': pages}
            )
            print(f"æœç´¢ç¬”è®°å¤±è´¥: {e}")
            return []
    
    def process_and_upload(self, responses, keyword):
        """å¤„ç†æ•°æ®å¹¶ä¸Šä¼ """
        start_time = time.time()
        # å¼€å§‹å¤„ç†å‰æ£€æŸ¥å†…å­˜
        self.memory_monitor.check_memory(print_info=True)
        
        total_notes = 0
        processed_count = 0
        ai_paraphrased_count = 0
        upload_success_count = 0
        upload_fail_count = 0
        
        nowt = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        
        # åˆ›å»ºä¿å­˜ç›®å½•ç»“æ„: saved/æ—¶é—´æˆ³/å›¾ç‰‡ã€åŸæ–‡ã€è½¬è¿°
        base_dir = os.path.join("saved", nowt)
        images_dir = os.path.join(base_dir, "å›¾ç‰‡")
        original_dir = os.path.join(base_dir, "åŸæ–‡")
        paraphrased_dir = os.path.join(base_dir, "è½¬è¿°")
        
        os.makedirs(images_dir, exist_ok=True)
        os.makedirs(original_dir, exist_ok=True)
        os.makedirs(paraphrased_dir, exist_ok=True)
        
        print(f"ä¿å­˜ç›®å½•: {base_dir}")
        
        csv_filename = os.path.join(base_dir, f"{keyword}_{nowt}.csv")
        
        with open(csv_filename, 'w', encoding='utf-8-sig', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["é¤å…åç§°", "åŸå§‹æè¿°", "å›¾ç‰‡é“¾æ¥", "ç¬”è®°ID", "è½¬è¿°æ ‡é¢˜", "è½¬è¿°æè¿°", "åœ°å€", "æ¸…æ´—åå›¾ç‰‡"])
            
            for response in responses:
                try:
                    if isinstance(response, str):
                        response_data = json.loads(response)
                    else:
                        response_data = response
                    
                    if 'data' in response_data and 'items' in response_data['data']:
                        notes = response_data['data']['items']
                        total_notes += len(notes)
                        
                        for note in notes:
                            try:
                                note_id = note.get("id")
                                xsec_token = note.get("xsec_token")
                                
                                if note_id and xsec_token:
                                    title, desc, img = self.get_note_detail(note_id, xsec_token)
                                    if title:
                                        # ä¿å­˜åŸæ–‡
                                        original_filename = os.path.join(original_dir, f"{processed_count:04d}_{note_id}.txt")
                                        with open(original_filename, 'w', encoding='utf-8') as f:
                                            f.write(f"æ ‡é¢˜: {title}\n\n")
                                            f.write(f"æè¿°: {desc}\n")
                                        print(f"\nğŸ“ æ­£åœ¨å¤„ç†ç¬”è®°: {title[:50]}...")
                                        
                                        # æå–é¤å…ä¿¡æ¯
                                        print(f"ğŸ” æ­£åœ¨æå–é¤å…ä¿¡æ¯...")
                                        # AIè°ƒç”¨å‰æ£€æŸ¥å†…å­˜ï¼Œå†…å­˜ä¸è¶³æ—¶ç»ˆæ­¢
                                        try:
                                            self.memory_monitor.check_memory(print_info=True, raise_on_critical=True)
                                        except MemoryError as e:
                                            print(f"\nâŒ å†…å­˜ä¸è¶³ï¼Œç»ˆæ­¢ç¨‹åº: {e}")
                                            raise
                                        
                                        extract_start = time.time()
                                        restaurants = self.ai_paraphraser.extract_restaurants(title, desc)
                                        extract_duration = time.time() - extract_start
                                        self.perf_monitor.record_metric(
                                            'ai.extract_restaurants',
                                            extract_duration,
                                            {
                                                'restaurant_count': len(restaurants),
                                                'memory_mb': self.perf_monitor.get_memory_usage(),
                                                'cpu_percent': self.perf_monitor.get_cpu_usage()
                                            }
                                        )
                                        
                                        if not restaurants:
                                            # å¦‚æœæ²¡æœ‰æå–åˆ°é¤å…ï¼Œä½¿ç”¨åŸæ¥çš„æ–¹å¼å¤„ç†ï¼ˆä½œä¸ºå•ä¸ªæ¡ç›®ï¼‰
                                            print(f"âš ï¸  æœªæå–åˆ°é¤å…ä¿¡æ¯ï¼ŒæŒ‰åŸç¬”è®°å¤„ç†")
                                            restaurants = [{
                                                'name': title,
                                                'address': '',
                                                'price_range': '',
                                                'description': desc
                                            }]
                                        
                                        print(f"âœ… æå–åˆ° {len(restaurants)} ä¸ªé¤å…")
                                        
                                        # åŸå¸–å›¾ç‰‡ä¸å†å¤„ç†ï¼Œæ¯ä¸ªé¤å…ä¼šå•ç‹¬æœç´¢å›¾ç‰‡
                                        
                                        # ä¸ºæ¯ä¸ªé¤å…åˆ†åˆ«è½¬è¿°å’Œä¸Šä¼ 
                                        for restaurant_idx, restaurant in enumerate(restaurants):
                                            restaurant_name = restaurant.get('name', 'æœªçŸ¥é¤å…')
                                            restaurant_address = restaurant.get('address', '')
                                            print(f"\nğŸ´ æ­£åœ¨å¤„ç†é¤å… {restaurant_idx + 1}/{len(restaurants)}: {restaurant_name}")
                                            
                                            # æœç´¢é¤å…å›¾ç‰‡ï¼ˆä¸­é—´æ— æ–‡å­—çš„å›¾ç‰‡ï¼‰
                                            # å¦‚æœæœç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå¸–ç¬¬ä¸€å¼ å›¾ç‰‡ä½œä¸ºå¤‡é€‰
                                            img_start = time.time()
                                            restaurant_safe_name = restaurant_name.replace('/', '_').replace('\\', '_')[:50]
                                            img_filename = f"{processed_count:04d}_{note_id}_{restaurant_idx}_{restaurant_safe_name}.jpg"
                                            img_path = os.path.join(images_dir, img_filename)
                                            
                                            # è·å–åŸå¸–ç¬¬ä¸€å¼ å›¾ç‰‡ä½œä¸ºå¤‡é€‰
                                            fallback_img_url = None
                                            if img:
                                                img_list = img.split(',')
                                                if img_list:
                                                    fallback_img_url = img_list[0].strip()
                                            
                                            saved_image_path = self.image_processor.process_restaurant_image(
                                                restaurant_name=restaurant_name,
                                                restaurant_address=restaurant_address,
                                                save_path=img_path,
                                                fallback_image_url=fallback_img_url
                                            )
                                            img_duration = time.time() - img_start
                                            
                                            if not saved_image_path:
                                                print(f"âš ï¸  æ— æ³•è·å–é¤å…å›¾ç‰‡ï¼Œè·³è¿‡: {restaurant_name}")
                                                continue
                                            
                                            saved_image_paths = [saved_image_path]
                                            self.perf_monitor.record_metric(
                                                'image.search_and_download',
                                                img_duration,
                                                {'memory_mb': self.perf_monitor.get_memory_usage()}
                                            )
                                            
                                            # å¯¹é¤å…è¿›è¡Œè½¬è¿°
                                            # AIè°ƒç”¨å‰æ£€æŸ¥å†…å­˜ï¼Œå†…å­˜ä¸è¶³æ—¶ç»ˆæ­¢
                                            try:
                                                self.memory_monitor.check_memory(print_info=False, raise_on_critical=True)
                                            except MemoryError as e:
                                                print(f"\nâŒ å†…å­˜ä¸è¶³ï¼Œç»ˆæ­¢ç¨‹åº: {e}")
                                                raise
                                            
                                            paraphrase_start = time.time()
                                            paraphrased_title, paraphrased_desc, type_cid = self.ai_paraphraser.paraphrase_restaurant(restaurant, title)
                                            paraphrase_duration = time.time() - paraphrase_start
                                            self.perf_monitor.record_metric(
                                                'ai.paraphrase_restaurant',
                                                paraphrase_duration,
                                                {
                                                    'memory_mb': self.perf_monitor.get_memory_usage(),
                                                    'cpu_percent': self.perf_monitor.get_cpu_usage(),
                                                    'restaurant_name': restaurant_name
                                                }
                                            )
                                            
                                            if not paraphrased_title:
                                                print(f"âš ï¸  é¤å…è½¬è¿°å¤±è´¥ï¼Œè·³è¿‡")
                                                continue
                                            
                                            if not type_cid:
                                                print(f"âŒ AIåˆ†ç±»å¤±è´¥ï¼Œè·³è¿‡è¯¥é¤å…: {restaurant_name}")
                                                continue
                                            else:
                                                print(f"âœ… AIåˆ†ç±»å®Œæˆ: å­ç±»å‹ID={type_cid}")
                                            
                                            # ä¿å­˜è½¬è¿°å†…å®¹ï¼ˆæ¯ä¸ªé¤å…å•ç‹¬ä¿å­˜ï¼‰
                                            paraphrased_filename = os.path.join(paraphrased_dir, f"{processed_count:04d}_{note_id}_{restaurant_idx}_{restaurant_safe_name}.txt")
                                            with open(paraphrased_filename, 'w', encoding='utf-8') as f:
                                                f.write(f"é¤å…åç§°: {restaurant_name}\n\n")
                                                f.write(f"æ ‡é¢˜: {paraphrased_title}\n\n")
                                                f.write(f"æè¿°: {paraphrased_desc}\n")
                                                if restaurant.get('address'):
                                                    f.write(f"\nåœ°å€: {restaurant.get('address')}\n")
                                                if restaurant.get('price_range'):
                                                    f.write(f"\näººå‡: {restaurant.get('price_range')}\n")
                                            print(f"âœ… å·²ä¿å­˜è½¬è¿°: {paraphrased_filename}")
                                            
                                            # å†™å…¥CSVï¼ˆæ¯ä¸ªé¤å…ä¸€è¡Œï¼‰
                                            writer.writerow([
                                                restaurant_name,  # åŸå§‹æ ‡é¢˜ï¼ˆé¤å…åï¼‰
                                                restaurant.get('description', desc),  # åŸå§‹æè¿°
                                                img,  # åŸå§‹å›¾ç‰‡é“¾æ¥ï¼ˆä¿ç•™åŸå¸–å›¾ç‰‡é“¾æ¥ï¼‰
                                                f"{note_id}_{restaurant_idx}",  # ç¬”è®°ID_é¤å…ç´¢å¼•
                                                paraphrased_title,  # è½¬è¿°æ ‡é¢˜
                                                paraphrased_desc,  # è½¬è¿°æè¿°
                                                restaurant.get('address', ''),  # åœ°å€ï¼ˆä½œä¸ºå†…å®¹ç±»å‹å­—æ®µï¼‰
                                                saved_image_path  # æœç´¢åˆ°çš„é¤å…å›¾ç‰‡
                                            ])
                                            
                                            # å‡†å¤‡æ•°æ®åº“æ•°æ®ï¼ˆæ¯ä¸ªé¤å…ä¸€æ¡è®°å½•ï¼‰
                                            # ç¡®ä¿çˆ¶ç±»å‹IDä¸ä¸ºç©ºï¼Œå¦‚æœé…ç½®ä¸­æ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼5
                                            type_pid = Config.DEFAULT_TYPE_PID if Config.DEFAULT_TYPE_PID is not None else 5
                                            
                                            # å¤„ç†å›¾ç‰‡è·¯å¾„ï¼šè½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„æˆ–URLæ ¼å¼
                                            img_paths_for_db = []
                                            if saved_image_path:
                                                if os.path.isabs(saved_image_path):
                                                    # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºcrawler-toolç›®å½•ï¼‰
                                                    crawler_tool_dir = os.path.dirname(os.path.abspath(__file__))
                                                    try:
                                                        rel_path = os.path.relpath(saved_image_path, crawler_tool_dir)
                                                        rel_path = rel_path.replace('\\', '/')
                                                        if not rel_path.startswith('./') and not rel_path.startswith('../'):
                                                            rel_path = './' + rel_path
                                                        img_paths_for_db.append(rel_path)
                                                    except ValueError:
                                                        img_paths_for_db.append(os.path.basename(saved_image_path))
                                                else:
                                                    # å·²ç»æ˜¯ç›¸å¯¹è·¯å¾„
                                                    saved_image_path = saved_image_path.replace('\\', '/')
                                                    if not saved_image_path.startswith('./') and not saved_image_path.startswith('../') and not saved_image_path.startswith('/'):
                                                        saved_image_path = './' + saved_image_path
                                                    img_paths_for_db.append(saved_image_path)
                                            
                                            tweet = {
                                                'tweets_title': paraphrased_title,
                                                'tweets_content': paraphrased_desc,
                                                'tweets_describe': paraphrased_desc[:200] if len(paraphrased_desc) > 200 else paraphrased_desc,
                                                'tweets_img': json.dumps(img_paths_for_db) if img_paths_for_db else json.dumps([]),
                                                'tweets_type_pid': type_pid,
                                                'tweets_type_cid': type_cid,  # ä½¿ç”¨AIè¿”å›çš„å­ç±»å‹ID
                                                'tweets_user': get_random_username(),  # éšæœºç”Ÿæˆç”¨æˆ·å
                                                # æ·»åŠ éšæœºæ•°ï¼šæµè§ˆé‡ã€ç‚¹èµé‡ã€æ”¶è—é‡
                                                'browse_num': random.randint(50, 500),   # æµè§ˆé‡ï¼š50-500
                                                'like_num': random.randint(5, 100),      # ç‚¹èµé‡ï¼š5-100
                                                'collect_num': random.randint(2, 50),   # æ”¶è—é‡ï¼š2-50
                                            }
                                            
                                            # ç«‹å³ä¸Šä¼ åˆ°æ•°æ®åº“
                                            upload_start = time.time()
                                            try:
                                                prepared_tweet = prepare_tweet_data(tweet)
                                                tweet_id = insert_tweet(prepared_tweet)
                                                upload_duration = time.time() - upload_start
                                                if tweet_id:
                                                    upload_success_count += 1
                                                    print(f"âœ… ä¸Šä¼ è‡³æ•°æ®åº“å®Œæˆ (ID: {tweet_id}) - {restaurant_name}")
                                                    self.perf_monitor.record_metric(
                                                        'db.insert_tweet',
                                                        upload_duration,
                                                        {
                                                            'success': True,
                                                            'tweet_id': tweet_id,
                                                            'memory_mb': self.perf_monitor.get_memory_usage()
                                                        }
                                                    )
                                                else:
                                                    upload_fail_count += 1
                                                    print(f"âŒ ä¸Šä¼ è‡³æ•°æ®åº“å¤±è´¥: è¿”å›IDä¸ºç©º - {restaurant_name}")
                                                    self.perf_monitor.record_metric(
                                                        'db.insert_tweet.error',
                                                        upload_duration,
                                                        {'error': 'è¿”å›IDä¸ºç©º'}
                                                    )
                                            except Exception as e:
                                                upload_duration = time.time() - upload_start
                                                upload_fail_count += 1
                                                print(f"âŒ ä¸Šä¼ è‡³æ•°æ®åº“å¤±è´¥: {e} - {restaurant_name}")
                                                self.perf_monitor.record_metric(
                                                    'db.insert_tweet.error',
                                                    upload_duration,
                                                    {'error': str(e)}
                                                )
                                            
                                            processed_count += 1
                                            ai_paraphrased_count += 1
                                            
                                            if processed_count % Config.BATCH_SIZE == 0:
                                                file.flush()
                                                print(f"å·²å¤„ç† {processed_count} æ¡æ•°æ®")
                                                # æ¯æ‰¹å¤„ç†åæ£€æŸ¥å†…å­˜
                                                self.memory_monitor.check_memory(print_info=True)
                                                self.random_delay(3, 6)
                            except KeyboardInterrupt:
                                print(f"\nâš ï¸  åœ¨å¤„ç†ç¬¬ {processed_count + 1} æ¡æ•°æ®æ—¶è¢«ä¸­æ–­")
                                print(f"å·²å¤„ç† {processed_count} æ¡æ•°æ®")
                                raise
                            except (MemoryError, Exception) as e:
                                # å¦‚æœæ˜¯å†…å­˜ä¸è¶³æˆ–AIæ¨¡å‹ä¸å¯ç”¨çš„é”™è¯¯ï¼Œç›´æ¥ç»ˆæ­¢ç¨‹åº
                                if isinstance(e, MemoryError) or "AIæ¨¡å‹ä¸å¯ç”¨" in str(e):
                                    print(f"\nâŒ {e}")
                                    print("ç¨‹åºç»ˆæ­¢")
                                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢ç¨‹åº
                                print(f"å¤„ç†å•æ¡æ•°æ®æ—¶å‡ºé”™: {e}")
                                continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€æ¡
                except KeyboardInterrupt:
                    print(f"\nâš ï¸  åœ¨å¤„ç†å“åº”æ—¶è¢«ä¸­æ–­")
                    print(f"å·²å¤„ç† {processed_count} æ¡æ•°æ®")
                    raise
                except (MemoryError, Exception) as e:
                    # å¦‚æœæ˜¯å†…å­˜ä¸è¶³æˆ–AIæ¨¡å‹ä¸å¯ç”¨çš„é”™è¯¯ï¼Œç›´æ¥ç»ˆæ­¢ç¨‹åº
                    if isinstance(e, MemoryError) or "AIæ¨¡å‹ä¸å¯ç”¨" in str(e):
                        print(f"\nâŒ {e}")
                        print("ç¨‹åºç»ˆæ­¢")
                        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢ç¨‹åº
                    print(f"å¤„ç†å“åº”æ—¶å‡ºç°é”™è¯¯: {e}")
        
        print(f"\næ€»å…±å¤„ç†äº† {total_notes} æ¡ç¬”è®°ï¼ŒæˆåŠŸä¿å­˜ {processed_count} æ¡é¤å…æ•°æ®")
        print(f"ä¿å­˜ä½ç½®: {base_dir}")
        print(f"AIè½¬è¿°æˆåŠŸ: {ai_paraphrased_count} æ¡")
        print(f"æ•°æ®åº“ä¸Šä¼ : æˆåŠŸ {upload_success_count} æ¡, å¤±è´¥ {upload_fail_count} æ¡")
        
        # è®°å½•æ•´ä½“å¤„ç†æ€§èƒ½
        total_duration = time.time() - start_time
        self.perf_monitor.record_metric(
            'crawler.process_and_upload',
            total_duration,
            {
                'total_notes': total_notes,
                'processed_count': processed_count,
                'ai_paraphrased_count': ai_paraphrased_count,
                'upload_success_count': upload_success_count,
                'upload_fail_count': upload_fail_count,
                'keyword': keyword,
                'memory_mb': self.perf_monitor.get_memory_usage(),
                'cpu_percent': self.perf_monitor.get_cpu_usage()
            }
        )
        
        return csv_filename
    
    def login(self):
        """æ‰‹åŠ¨ç™»å½•å°çº¢ä¹¦"""
        self.page.get('https://www.xiaohongshu.com')
        print('è¯·æ‰«ç ç™»å½•å°çº¢ä¹¦')
        print('ç™»å½•å®ŒæˆåæŒ‰å›è½¦ç»§ç»­...')
        input()
        time.sleep(3)
    
    def run(self, keyword, pages):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        try:
            # å¯åŠ¨å†…å­˜ç›‘æ§
            self.memory_monitor.start_monitoring()
            # åˆå§‹å†…å­˜æ£€æŸ¥
            self.memory_monitor.check_memory(print_info=True)
            
            self.login()
            
            print(f"\nå¼€å§‹æŠ“å–å…³é”®è¯ï¼š{keyword}")
            print(f"é¢„è®¡æŠ“å– {pages} é¡µæ•°æ®")
            print("=" * 60)
            print("æç¤º: æŒ‰ Ctrl+C å¯ä»¥éšæ—¶ç»ˆæ­¢ç¨‹åº")
            
            responses = self.search_notes(keyword, pages)
            if responses:
                filename = self.process_and_upload(responses, keyword)
                print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°ï¼š{filename}")
                
                # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡æç¤º
                print("\n" + "=" * 60)
                print("ğŸ“Š æ€§èƒ½ç›‘æ§æ•°æ®å·²è®°å½•")
                print("æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡ï¼špython performance_monitor.py")
                print("å¯¼å‡ºæ€§èƒ½æ•°æ®ï¼špython performance_monitor.py --export performance.json")
                print("=" * 60)
            else:
                print("æœªè·å–åˆ°ä»»ä½•æ•°æ®")
                
        except KeyboardInterrupt:
            print("\n\nâš ï¸  æ£€æµ‹åˆ° Ctrl+Cï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
            print("æ­£åœ¨ä¿å­˜å·²å¤„ç†çš„æ•°æ®...")
            print("æ­£åœ¨å…³é—­æµè§ˆå™¨...")
            raise  # é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚ä¹Ÿèƒ½æ•è·
        except MemoryError as e:
            print(f"\nâŒ å†…å­˜ä¸è¶³å¯¼è‡´ç¨‹åºç»ˆæ­¢: {e}")
            raise  # é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚ä¹Ÿèƒ½æ•è·
        except Exception as e:
            print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        finally:
            # åœæ­¢å†…å­˜ç›‘æ§å¹¶æ‰“å°æ‘˜è¦
            self.memory_monitor.stop_monitoring()
            self.memory_monitor.print_summary()
            
            try:
                self.page.close()
                print("âœ… æµè§ˆå™¨å·²å…³é—­")
            except:
                pass


def main():
    """ä¸»å‡½æ•° - ä¸€é”®è¿è¡Œ"""
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python crawler.py <å…³é”®è¯> <é¡µæ•°>")
        print("ç¤ºä¾‹: python crawler.py æ·±åœ³ç¾é£Ÿ 5")
        sys.exit(1)
    
    keyword = sys.argv[1]
    try:
        pages = int(sys.argv[2])
    except ValueError:
        print("é”™è¯¯: é¡µæ•°å¿…é¡»æ˜¯æ•°å­—")
        sys.exit(1)
    
    print("=" * 60)
    print("é›†æˆçˆ¬è™«ç³»ç»Ÿ")
    print("åŠŸèƒ½: çˆ¬è™« â†’ AIè½¬è¿° â†’ æ°´å°æ¸…æ´— â†’ è‡ªåŠ¨ä¸Šä¼ ")
    print(f"æ¨¡å‹: {Config.LLM_MODEL}")
    print("=" * 60)
    print()
    
    spider = None
    try:
        spider = IntegratedSpider()
        spider.run(keyword, pages)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
        print("æ­£åœ¨æ¸…ç†èµ„æº...")
        if spider:
            try:
                spider.page.close()
            except:
                pass
        print("âœ… ç¨‹åºå·²å®‰å…¨é€€å‡º")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        if spider:
            try:
                spider.page.close()
            except:
                pass
        sys.exit(1)


if __name__ == '__main__':
    main()

